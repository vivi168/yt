#!/usr/bin/env python
import sys
from subprocess import call
from bs4 import BeautifulSoup
import urllib.parse
import urllib.request


def getLinks(url):
    webpage = urllib.request.urlopen(url)
    soup = BeautifulSoup(webpage, "html.parser")
    links = [];
    for anchor in soup.find_all('a', { "class": "yt-uix-tile-link" } ):
        link = [];
        link.append(anchor.get('title'))
        link.append("http://www.youtube.com" + anchor.get('href'))
        links.append(link)
        #print(link)

    for i, link in enumerate(links):
        print(str(i) + ' ' + link[0])

    n = -1;
    while n > len(links)-1 or n < 0:
        n = input('choose a link (#) or (q)uit ')
        if n == 'q':
            sys.exit()
        n = int(n)

    print(links[n])
    call(["youtube-dl", links[n][1]])


if len(sys.argv) > 2:
    if sys.argv[1] == '-s':
        query_string = urllib.parse.urlencode({"search_query": sys.argv[2]})
        print(query_string)

        url = 'http://youtube.com/results?' + query_string

    elif sys.argv[1] == '-c':

        url = 'http://youtube.com/user/' + sys.argv[2] + '/videos'

    else:
        sys.exit()

    getLinks(url)

else:
    print("usage:" + sys.argv[0] + " -s query_string || -c yt channel_name")
    sys.exit()
